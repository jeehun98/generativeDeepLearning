{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "jEruggY2wXXw",
        "outputId": "6f9d58cf-1f30-491b-e17a-65b379b348fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-01cd3755b1e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAE\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from utils.loaders import load_mnist\n",
        "from models.AE import Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행 매개변수\n",
        "SECTION = 'vae'\n",
        "RUN_ID = '0001'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "MODE =  'build' #'load' #"
      ],
      "metadata": {
        "id": "Qe879cr50i1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ],
      "metadata": {
        "id": "dAMTI1WO0jpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AE = Autoencoder(\n",
        "    input_dim = (28,28,1)\n",
        "    , encoder_conv_filters = [32,64,64, 64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,1]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 2\n",
        ")\n",
        "\n",
        "if MODE == 'build':\n",
        "    AE.save(RUN_FOLDER)\n",
        "else:\n",
        "    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "metadata": {
        "id": "nXkt0m8R0kXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AE.encoder.summary()"
      ],
      "metadata": {
        "id": "jKOBS5HT0lRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "BATCH_SIZE = 32\n",
        "INITIAL_EPOCH = 0"
      ],
      "metadata": {
        "id": "H5jeCdFtA9xi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AE.compile(LEARNING_RATE)"
      ],
      "metadata": {
        "id": "vCEHd6JkA_IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AE.train(     \n",
        "    x_train[:1000]\n",
        "    , batch_size = BATCH_SIZE\n",
        "    , epochs = 200\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ],
      "metadata": {
        "id": "Pvt68eWjA_9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "오토인코더 분석"
      ],
      "metadata": {
        "id": "hGmcsR_uBKsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 적재"
      ],
      "metadata": {
        "id": "Vv9rYXa5BOTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ],
      "metadata": {
        "id": "gYRNeI9RBJ-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구조 호출"
      ],
      "metadata": {
        "id": "T1qvn2YXBPeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AE = load_model(Autoencoder, RUN_FOLDER)"
      ],
      "metadata": {
        "id": "Gc0ZKgJbBJHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본 그림 재구성"
      ],
      "metadata": {
        "id": "TAqgIo4zBRmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_to_show = 10\n",
        "np.random.seed(88)\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "\n",
        "z_points = AE.encoder.predict(example_images)\n",
        "\n",
        "reconst_images = AE.decoder.predict(z_points)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = example_images[i].squeeze()\n",
        "    ax = fig.add_subplot(2, n_to_show, i+1)\n",
        "    ax.axis('off')\n",
        "    ax.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=ax.transAxes)\n",
        "    ax.imshow(img, cmap='gray_r')\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = reconst_images[i].squeeze()\n",
        "    ax = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(img, cmap='gray_r')"
      ],
      "metadata": {
        "id": "XsxJgR8gBJeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "변이형 오토인코더 훈련"
      ],
      "metadata": {
        "id": "Y4S7keY3W05K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 적재"
      ],
      "metadata": {
        "id": "kLbo-bY4W2iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ],
      "metadata": {
        "id": "4QQJFMgEW3Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성"
      ],
      "metadata": {
        "id": "WCLtU1kIW4L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VariationalAutoencoder(\n",
        "    input_dim = (28,28,1)\n",
        "    , encoder_conv_filters = [32,64,64, 64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,1]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 2\n",
        ")\n",
        "\n",
        "if mode == 'build':\n",
        "    vae.save(RUN_FOLDER)\n",
        "else:\n",
        "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "metadata": {
        "id": "Sm35h95NW4zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 훈련"
      ],
      "metadata": {
        "id": "Cc7lIZx1W7iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "R_LOSS_FACTOR = 1000"
      ],
      "metadata": {
        "id": "HJRofMZ7W8IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)"
      ],
      "metadata": {
        "id": "RufJUAcxW85g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "PRINT_EVERY_N_BATCHES = 100\n",
        "INITIAL_EPOCH = 0"
      ],
      "metadata": {
        "id": "xUF1VWLfW-u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.train(     \n",
        "    x_train\n",
        "    , batch_size = BATCH_SIZE\n",
        "    , epochs = EPOCHS\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ],
      "metadata": {
        "id": "znCfHQZYW_gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "변이형 오토인코더 훈련 - 얼굴 데이터셋"
      ],
      "metadata": {
        "id": "RrGqT6GIYhlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 적재"
      ],
      "metadata": {
        "id": "TRsWgJ8xYpB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = (128,128,3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
        "\n",
        "NUM_IMAGES = len(filenames)"
      ],
      "metadata": {
        "id": "QfwqEKS5YqXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
        "                                         , target_size = INPUT_DIM[:2]\n",
        "                                         , batch_size = BATCH_SIZE\n",
        "                                         , shuffle = True\n",
        "                                         , class_mode = 'input'\n",
        "                                         , subset = \"training\"\n",
        "                                            )"
      ],
      "metadata": {
        "id": "LZWUk5FzYrTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성"
      ],
      "metadata": {
        "id": "iMuaH3L2YtVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VariationalAutoencoder(\n",
        "                input_dim = INPUT_DIM\n",
        "                , encoder_conv_filters=[32,64,64, 64]\n",
        "                , encoder_conv_kernel_size=[3,3,3,3]\n",
        "                , encoder_conv_strides=[2,2,2,2]\n",
        "                , decoder_conv_t_filters=[64,64,32,3]\n",
        "                , decoder_conv_t_kernel_size=[3,3,3,3]\n",
        "                , decoder_conv_t_strides=[2,2,2,2]\n",
        "                , z_dim=200\n",
        "                , use_batch_norm=True\n",
        "                , use_dropout=True)\n",
        "\n",
        "if mode == 'build':\n",
        "    vae.save(RUN_FOLDER)\n",
        "else:\n",
        "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "metadata": {
        "id": "INyDRqlPYsxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.encoder.summary()"
      ],
      "metadata": {
        "id": "hLkg_9BPYvn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.decoder.summary()"
      ],
      "metadata": {
        "id": "I90WphoQYxWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 적재"
      ],
      "metadata": {
        "id": "IvjPmpDHcK1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = (128,128,3)\n",
        "\n",
        "att = pd.read_csv(os.path.join(DATA_FOLDER, 'list_attr_celeba.csv'))\n",
        "\n",
        "imageLoader = ImageLabelLoader(IMAGE_FOLDER, INPUT_DIM[:2])"
      ],
      "metadata": {
        "id": "48g9Y-4PcLqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "얼굴 이미지 재구성"
      ],
      "metadata": {
        "id": "wSqO9YTucGnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_to_show = 10\n",
        "\n",
        "data_flow_generic = imageLoader.build(att, n_to_show)\n",
        "\n",
        "example_batch = next(data_flow_generic)\n",
        "example_images = example_batch[0]\n",
        "\n",
        "z_points = vae.encoder.predict(example_images)\n",
        "\n",
        "reconst_images = vae.decoder.predict(z_points)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = example_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
        "    sub.axis('off')        \n",
        "    sub.imshow(img)\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = reconst_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "    sub.axis('off')\n",
        "    sub.imshow(img)"
      ],
      "metadata": {
        "id": "qsB5p_9ocI4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
        "\n",
        "x = encoder_input\n",
        "\n",
        "for i in range(self.n_layers_encoder):\n",
        "  conv_layer = Conv2D(\n",
        "      filters = self.encoder_conv_filters[i],\n",
        "      kernel_size = self.encoder_conv_kernel_size[i],\n",
        "      strides = self.encoder_conv_strides[i],\n",
        "      padding = 'same',\n",
        "      name = 'encoder_conv_' + str(i)\n",
        "  )\n",
        "\n",
        "  x = conv_layer(x)\n",
        "  x = LeakyReLU()(x)\n",
        "\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "x = Flatten()(x)\n",
        "\n",
        "encoder_output = Dense(self.z_dim, name='encoder_output')(x)\n",
        "self.encoder = Model(encoder_input, encoder_output)"
      ],
      "metadata": {
        "id": "NYMph8BeVdzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = Input(shape=(self.z_dim), name='decoder_input')\n",
        "\n",
        "x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = Reshape(shape_before_flattening)(x)\n",
        "\n",
        "for i in range(self.n_layers_decoder):\n",
        "  conv_layer = Conv2DTranspose(\n",
        "      filters = self.decoder_conv_filters[i],\n",
        "      kernel_size = self.decoder_conv_kernel_size[i],\n",
        "      strides = self.decoder_conv_strides[i],\n",
        "      padding = 'same',\n",
        "      name = 'decoder_conv_' + str(i)\n",
        "  )\n",
        "\n",
        "  x = conv_t_layer(x)\n",
        "  \n",
        "  if i < self.n_layers_decoder - 1:\n",
        "    x = LeakyReLU()(x)\n",
        "  else:\n",
        "    x=Activation('sigmoid')(x)\n",
        "\n",
        "decoder_output = x\n",
        "\n",
        "self.decoder = Model(decoder_input, decoder_output)"
      ],
      "metadata": {
        "id": "tV3JPhhV4CKH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}